{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7eb475-a93e-460d-9ba0-b88f91993bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.7.tar.gz (317.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.4/317.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.7-py2.py3-none-any.whl size=317907716 sha256=cd12f738cf43f24434770034a947a8d72d0eb1721a2d6d8fefe1e042bef5bc85\n",
      "  Stored in directory: /opt/work/.cache/pip/wheels/90/7b/3a/f4e0b629a2ec0ac23c6ea92ee30d7fb269def367fd9f70bcf9\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f545f1-81e6-49dd-bbf6-156a140921fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/08 15:52:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/08 15:52:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3769993fe35f:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>IcebergMinimal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x747567c8df70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"IcebergMinimal\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.rest\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.rest.type\", \"rest\")\n",
    "    .config(\"spark.sql.catalog.rest.uri\", \"http://iceberg-rest:8181\")\n",
    "    .config(\"spark.sql.catalog.rest.warehouse\", \"s3://lake/warehouse\")\n",
    "    .config(\"spark.sql.catalog.rest.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .config(\"spark.sql.catalog.rest.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.rest.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.rest.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.rest.s3.secret-access-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.rest.s3.region\", \"us-east-1\")\n",
    "    .config(\"spark.sql.defaultCatalog\", \"rest\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8637bc8f-1c35-4d9b-9cea-090d32e58ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|raw      |\n",
      "|silver   |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES IN rest\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fcbfca6-a49e-4fb9-9e62-e72535f8d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|silver   |listings_all|false      |\n",
      "+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN rest.silver\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a5804d21-7789-4596-9e26-72b4f80aafb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|2524    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM rest.raw.mubawab\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f12df6f8-8864-4c20-a8d2-d2f478a30d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|3745    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM rest.raw.avito\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c483070b-f898-469f-8c43-5be5cfc65384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"TRUNCATE TABLE rest.silver.listings_all\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fcd8c8e8-f83a-4bd1-b75c-eddf757298c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## spark.sql(\"DROP TABLE rest.silver.listings_all\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8e59c9ed-471f-40d1-b255-11e9c3ca7111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 558:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|0       |\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM rest.silver.listings_all\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "62ff83a4-0d02-4eec-959a-bafe5ef03f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver = spark.sql(\"SELECT * FROM rest.silver.listings_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "66937ead-abc2-4732-9be4-fca226c01816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver.select(\"url\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d03612d-1825-475a-a7d7-be80c1da0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After de-duplication: 3436\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, row_number\n",
    "\n",
    "# keep latest per URL\n",
    "w = Window.partitionBy(\"url\").orderBy(col(\"ingest_ts\").desc())\n",
    "\n",
    "silver_dedup = (\n",
    "    silver\n",
    "    .withColumn(\"rn\", row_number().over(w))\n",
    "    .filter(col(\"rn\") == 1)\n",
    "    .drop(\"rn\")\n",
    ")\n",
    "\n",
    "# verify\n",
    "print(\"After de-duplication:\", silver_dedup.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "38f67a95-a5ae-481a-b45c-80eb57d81f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|site   |count|\n",
      "+-------+-----+\n",
      "|avito  |3991 |\n",
      "|mubawab|2341 |\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"count\").desc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f765a0e5-ffb1-42ca-a665-e9fc25366486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- error: string (nullable = true)\n",
      " |-- ingest_ts: timestamp (nullable = true)\n",
      " |-- site: string (nullable = false)\n",
      " |-- offre: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- equipments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description_text: string (nullable = true)\n",
      " |-- offre_match: boolean (nullable = true)\n",
      " |-- surface_habitable: string (nullable = true)\n",
      " |-- caution: string (nullable = true)\n",
      " |-- zoning: string (nullable = true)\n",
      " |-- type_d_appartement: string (nullable = true)\n",
      " |-- standing: string (nullable = true)\n",
      " |-- surface_totale: string (nullable = true)\n",
      " |-- etage: string (nullable = true)\n",
      " |-- age_du_bien: string (nullable = true)\n",
      " |-- nombre_de_pieces: string (nullable = true)\n",
      " |-- chambres: string (nullable = true)\n",
      " |-- salle_de_bain: string (nullable = true)\n",
      " |-- frais_de_syndic_mois: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- nombre_d_etage: string (nullable = true)\n",
      " |-- disponibilite: string (nullable = true)\n",
      " |-- salons: string (nullable = true)\n",
      " |-- features_amenities_json: string (nullable = true)\n",
      " |-- type_de_terrain: string (nullable = true)\n",
      " |-- type_de_bien: string (nullable = true)\n",
      " |-- statut_du_terrain: string (nullable = true)\n",
      " |-- surface_de_la_parcelle: string (nullable = true)\n",
      " |-- type_du_sol: string (nullable = true)\n",
      " |-- etage_du_bien: string (nullable = true)\n",
      " |-- annees: string (nullable = true)\n",
      " |-- constructibilite: string (nullable = true)\n",
      " |-- livraison: string (nullable = true)\n",
      " |-- orientation: string (nullable = true)\n",
      " |-- etat: string (nullable = true)\n",
      " |-- nombre_d_etages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4deb6f02-5cda-47bd-b124-f72cbb2f832f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>error</th>\n",
       "      <th>ingest_ts</th>\n",
       "      <th>site</th>\n",
       "      <th>offre</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>seller</th>\n",
       "      <th>published_date</th>\n",
       "      <th>...</th>\n",
       "      <th>statut_du_terrain</th>\n",
       "      <th>surface_de_la_parcelle</th>\n",
       "      <th>type_du_sol</th>\n",
       "      <th>etage_du_bien</th>\n",
       "      <th>annees</th>\n",
       "      <th>constructibilite</th>\n",
       "      <th>livraison</th>\n",
       "      <th>orientation</th>\n",
       "      <th>etat</th>\n",
       "      <th>nombre_d_etages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8244102</td>\n",
       "      <td>https://www.mubawab.ma/fr/a/8244102/terrain-%C...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-08 16:02:30.003</td>\n",
       "      <td>mubawab</td>\n",
       "      <td>vente</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>Terrain √† vendre √† Route de Fez. Surface de 40...</td>\n",
       "      <td>elhajouy immo</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Titr√©</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                url error  \\\n",
       "0  8244102  https://www.mubawab.ma/fr/a/8244102/terrain-%C...  None   \n",
       "\n",
       "                ingest_ts     site  offre     price  \\\n",
       "0 2025-11-08 16:02:30.003  mubawab  vente  800000.0   \n",
       "\n",
       "                                               title         seller  \\\n",
       "0  Terrain √† vendre √† Route de Fez. Surface de 40...  elhajouy immo   \n",
       "\n",
       "  published_date  ... statut_du_terrain surface_de_la_parcelle type_du_sol  \\\n",
       "0           None  ...              None                   None        None   \n",
       "\n",
       "  etage_du_bien annees constructibilite livraison orientation  etat  \\\n",
       "0          None   None             None     Titr√©        None  None   \n",
       "\n",
       "  nombre_d_etages  \n",
       "0            None  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0f024-8121-4132-b58f-cd750b3980dc",
   "metadata": {},
   "source": [
    "## Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e25fb57-b7b0-4d3a-a25a-6ed492ebe14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    price|\n",
      "+---------+\n",
      "| 300000.0|\n",
      "| 330000.0|\n",
      "|   4800.0|\n",
      "|   1.66E7|\n",
      "|  18400.0|\n",
      "| 995000.0|\n",
      "|  15750.0|\n",
      "|1100000.0|\n",
      "| 165000.0|\n",
      "|  16800.0|\n",
      "+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.select(\"price\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fad0dfc4-24d0-4729-8d84-4f7b4381ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     price|\n",
      "+----------+\n",
      "|1500000000|\n",
      "| 650000000|\n",
      "| 410000000|\n",
      "| 230000000|\n",
      "| 162500000|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+\n",
      "|price|\n",
      "+-----+\n",
      "| NULL|\n",
      "|  125|\n",
      "|  130|\n",
      "|  200|\n",
      "|  249|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# overwrite the same column, no new dataset\n",
    "silver = silver.withColumn(\"price\", col(\"price\").cast(DecimalType(38, 0)))\n",
    "\n",
    "# verify\n",
    "silver.select(\"price\").distinct().orderBy(col(\"price\").desc()).show(5)\n",
    "silver.select(\"price\").distinct().orderBy(col(\"price\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a082eb6-74d2-45ef-b619-b72d2ebf8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|ingest_ts              |\n",
      "+-----------------------+\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:20.003|\n",
      "|2025-11-08 15:56:30.007|\n",
      "+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.select(\"ingest_ts\").orderBy(col(\"ingest_ts\")).show(10 , truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c7016dab-0cc3-49de-abe3-6f4947570efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"published_date\",\n",
    "    F.when(F.col(\"published_date\").isNull(), F.col(\"ingest_ts\"))\n",
    "     .otherwise(F.col(\"published_date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7d6f5d5e-8ad4-41fc-b5be-cbf451e59ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|null_published|total|\n",
      "+--------------+-----+\n",
      "|             0| 6332|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.select(\n",
    "    F.count(F.when(F.col(\"published_date\").isNull(), 1)).alias(\"null_published\"),\n",
    "    F.count(\"*\").alias(\"total\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1ffcde4-64a2-4659-8ed2-b900e0aeb165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------------+\n",
      "|id     |site   |published_date         |\n",
      "+-------+-------+-----------------------+\n",
      "|8245961|mubawab|2025-11-08 16:54:50.005|\n",
      "|8245969|mubawab|2025-11-08 16:54:50.005|\n",
      "|8245971|mubawab|2025-11-08 16:54:50.005|\n",
      "|8245980|mubawab|2025-11-08 16:54:50.005|\n",
      "|8245987|mubawab|2025-11-08 16:54:40.003|\n",
      "|8245989|mubawab|2025-11-08 16:54:40.003|\n",
      "|8245992|mubawab|2025-11-08 16:54:40.003|\n",
      "|8245997|mubawab|2025-11-08 16:54:40.003|\n",
      "|8246003|mubawab|2025-11-08 16:54:30.003|\n",
      "|8246008|mubawab|2025-11-08 16:54:30.003|\n",
      "|8246009|mubawab|2025-11-08 16:54:30.003|\n",
      "|8246010|mubawab|2025-11-08 16:54:30.003|\n",
      "|8246020|mubawab|2025-11-08 16:54:20.002|\n",
      "|8246023|mubawab|2025-11-08 16:54:20.002|\n",
      "|8246024|mubawab|2025-11-08 16:54:20.002|\n",
      "|8246029|mubawab|2025-11-08 16:54:20.002|\n",
      "|8246044|mubawab|2025-11-08 16:54:20.002|\n",
      "|8246045|mubawab|2025-11-08 16:54:10.005|\n",
      "|8246057|mubawab|2025-11-08 16:54:10.005|\n",
      "|8246069|mubawab|2025-11-08 16:54:10.005|\n",
      "+-------+-------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.select(\"id\", \"site\" , \"published_date\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ee837f3-30fb-4783-9d20-e72840ff07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|city          |count|\n",
      "+--------------+-----+\n",
      "|Jouamaa       |1    |\n",
      "|Inchaden      |1    |\n",
      "|Ziaida        |1    |\n",
      "|Dakhla        |1    |\n",
      "|Agadir Melloul|1    |\n",
      "|Imi Ouaddar   |1    |\n",
      "|Tnine Aglou   |1    |\n",
      "|La√§youne      |1    |\n",
      "|Oulad Dahou   |1    |\n",
      "|Oulad Frej    |1    |\n",
      "+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"city\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee2dfdaa-bd8a-4f6b-9a06-29560f293041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|city      |count|\n",
      "+----------+-----+\n",
      "|casablanca|2017 |\n",
      "|marrakech |984  |\n",
      "|rabat     |643  |\n",
      "|tanger    |613  |\n",
      "|mohammedia|231  |\n",
      "|kenitra   |202  |\n",
      "|agadir    |174  |\n",
      "|temara    |172  |\n",
      "|bouskoura |158  |\n",
      "|fes       |90   |\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, unicodedata\n",
    "from pyspark.sql.functions import col, trim, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
    "\n",
    "def _clean_base(s: str) -> str:\n",
    "    s = _unaccent(s or \"\").lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s'\\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "ARABIC = {\n",
    "    \"ÿßŸÑÿØÿßÿ± ÿßŸÑÿ®Ÿäÿ∂ÿßÿ°\": \"casablanca\",\n",
    "    \"ŸÖÿ±ÿßŸÉÿ¥\": \"marrakech\",\n",
    "    \"ÿ∑ŸÜÿ¨ÿ©\": \"tanger\",\n",
    "    \"ŸÅÿßÿ≥\": \"fes\",\n",
    "    \"Ÿàÿ¨ÿØÿ©\": \"oujda\",\n",
    "    \"ÿßŸÑŸÇŸÜŸäÿ∑ÿ±ÿ©\": \"kenitra\",\n",
    "    \"ÿßŸÑÿπŸäŸàŸÜ\": \"laayoune\",\n",
    "    \"ÿßŸÑÿ±ÿ®ÿßÿ∑\": \"rabat\",\n",
    "    \"ÿ≥ŸÑÿß\": \"sale\",\n",
    "    \"ÿ™ÿ∑ŸàÿßŸÜ\": \"tetouan\",\n",
    "}\n",
    "\n",
    "ALIASES = {\n",
    "    \"casa\": \"casablanca\", \"casa blanca\": \"casablanca\", \"casablance\": \"casablanca\",\n",
    "    \"marrakesh\": \"marrakech\",\n",
    "    \"tangier\": \"tanger\",\n",
    "    \"fez\": \"fes\",\n",
    "    \"k√©nitra\": \"kenitra\", \"kenitra\": \"kenitra\",\n",
    "    \"mekn√®s\": \"meknes\",\n",
    "    \"t√©touan\": \"tetouan\",\n",
    "    \"b√©ni mellal\": \"beni mellal\",\n",
    "    \"la√¢youne\": \"laayoune\", \"la√§youne\": \"laayoune\", \"laayoun\": \"laayoune\",\n",
    "    \"m'diq\": \"mdiq\", \"m diq\": \"mdiq\",\n",
    "    \"dche√Øra el jihadia\": \"dcheira el jihadia\",\n",
    "    \"inzegan\": \"inezgane\", \"inezgane\": \"inezgane\",\n",
    "    \"ait melloul\": \"ait melloul\",\n",
    "    \"dar bouazza\": \"dar bouazza\",\n",
    "    \"bouskoura\": \"bouskoura\",\n",
    "    \"harhoura\": \"harhoura\",\n",
    "    \"skhirat\": \"skhirat\",\n",
    "    \"tamesna\": \"tamesna\",\n",
    "    \"rabat\": \"rabat\",\n",
    "    \"sale\": \"sale\",\n",
    "}\n",
    "\n",
    "NULLY = {\"\", \"null\", \"none\", \"n/a\", \"nan\", \"tout le maroc\", \"toute la ville\"}\n",
    "\n",
    "def normalize_city_str(val: str) -> str:\n",
    "    if val is None:\n",
    "        return None\n",
    "    if val in ARABIC:\n",
    "        return ARABIC[val]\n",
    "    base = _clean_base(val)\n",
    "    if base in NULLY:\n",
    "        return None\n",
    "    # direct alias\n",
    "    if base in ALIASES:\n",
    "        return ALIASES[base]\n",
    "    # regex-based cleanup\n",
    "    base = base.replace(\"m diq\", \"mdiq\").replace(\"m' diq\", \"mdiq\")\n",
    "    if base in ALIASES:\n",
    "        return ALIASES[base]\n",
    "    return base or None\n",
    "\n",
    "normalize_city_udf = udf(normalize_city_str, StringType())\n",
    "\n",
    "# overwrite same column\n",
    "silver = silver.withColumn(\"city\", normalize_city_udf(trim(col(\"city\"))))\n",
    "\n",
    "# verify\n",
    "silver.groupBy(\"city\").count().orderBy(col(\"count\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f8a7b99b-f12b-4999-8f9c-a28c59e008bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver.select(\"city\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f05b78d0-d3ec-43f9-a05d-c19589f31e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|neighborhood    |count|\n",
      "+----------------+-----+\n",
      "|Fouarate        |1    |\n",
      "|Extension Dakhla|1    |\n",
      "|Al Filline      |1    |\n",
      "|Hoda            |1    |\n",
      "|Jawhara         |1    |\n",
      "|Hay Inara       |1    |\n",
      "|Azib Haj Kaddour|1    |\n",
      "|Les Orangers    |1    |\n",
      "|Hay Inbiat      |1    |\n",
      "|Technopolis     |1    |\n",
      "+----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"neighborhood\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2e3bec00-c650-4cd7-b4b0-a0931d63d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata, re\n",
    "from pyspark.sql.functions import col, trim, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# --- helpers\n",
    "def _fix_mojibake(s: str) -> str:\n",
    "    # common UTF-8 mojibake seen in scraped French/Arabic names\n",
    "    # (keep set short + pragmatic)\n",
    "    repl = {\n",
    "        \"√É¬©\": \"√©\", \"√É¬®\": \"√®\", \"√É¬™\": \"√™\", \"√É¬´\": \"√´\",\n",
    "        \"√É¬¢\": \"√¢\", \"√É¬§\": \"√§\", \"√É \": \"√†\", \"√É¬π\": \"√π\",\n",
    "        \"√É¬ª\": \"√ª\", \"√É¬º\": \"√º\", \"√É¬Ø\": \"√Ø\", \"√É¬Æ\": \"√Æ\",\n",
    "        \"√É¬¥\": \"√¥\", \"√É¬ß\": \"√ß\",\n",
    "        \"√É¬∂\": \"√∂\", \"√É¬±\": \"√±\",\n",
    "        \"√Ç¬∞\": \"¬∞\", \"√Ç‚Äô\": \"‚Äô\", \"√Ç¬´\": \"¬´\", \"√Ç¬ª\": \"¬ª\",\n",
    "        \"√Ç¬∑\": \"¬∑\", \"√Ç\": \"\",  # stray\n",
    "    }\n",
    "    for k,v in repl.items():\n",
    "        s = s.replace(k, v)\n",
    "    return s\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
    "\n",
    "NULLY = {\n",
    "    \"\", \"null\", \"none\", \"n/a\", \"nan\",\n",
    "    \"‚Äî\", \"-\", \".\", \"_\", \"?\", \"s/o\", \"n.c\", \"nc\"\n",
    "}\n",
    "\n",
    "# Canonical token normalizers (apply after lowercasing)\n",
    "TOKEN_FIXES = [\n",
    "    (r\"\\bain\\b\", \"ain\"),\n",
    "    (r\"\\ba√Øn\\b\", \"ain\"),\n",
    "    (r\"\\bha[iy]\\b\", \"hay\"),\n",
    "    (r\"\\bhayy\\b\", \"hay\"),\n",
    "    (r\"\\bz\\.?\\s*ind(ustrielle)?\\b\", \"zone industrielle\"),\n",
    "    (r\"\\bzone ind(ustrielle)?\\b\", \"zone industrielle\"),\n",
    "    (r\"\\bcentre[-\\s]?ville\\b\", \"centre ville\"),\n",
    "    (r\"\\bville[-\\s]?nouvelle\\b\", \"ville nouvelle\"),\n",
    "    (r\"\\bquartier[-\\s]administratif\\b\", \"quartier administratif\"),\n",
    "    (r\"\\bquartier[-\\s]du[-\\s]parc\\b\", \"quartier du parc\"),\n",
    "    (r\"\\bquartier[-\\s]des[-\\s]h[o√¥]pitaux\\b\", \"quartier des hopitaux\"),\n",
    "    (r\"\\b2\\s*mars\\b\", \"2 mars\"),\n",
    "    (r\"\\bcasablanca\\s*marina\\b\", \"casablanca marina\"),\n",
    "    (r\"\\broute\\s*d['‚Äô]\\s*\", \"route de \"),\n",
    "    (r\"\\bav\\s+\", \"avenue \"),\n",
    "    (r\"\\bav\\.?\\b\", \"avenue\"),\n",
    "    (r\"\\bbd\\b\", \"boulevard\"),\n",
    "    (r\"\\bval\\s*d['‚Äô]or\\b\", \"val d'or\"),\n",
    "    (r\"\\bp[ao]lmeraie\\b\", \"palmeraie\"),\n",
    "]\n",
    "\n",
    "# Big alias map (lowercase & unaccented keys -> canonical LOWERCASE)\n",
    "ALIASES = {\n",
    "    # high-frequency buckets in your printout\n",
    "    \"centre ville\": \"centre ville\",\n",
    "    \"centre\": \"centre\",\n",
    "    \"centre  ville\": \"centre ville\",\n",
    "    \"centre-ville\": \"centre ville\",\n",
    "\n",
    "    \"les princesses\": \"les princesses\",\n",
    "    \"les princesses \": \"les princesses\",\n",
    "    \"princesses\": \"les princesses\",\n",
    "    \"les princesses (maarif)\": \"les princesses\",\n",
    "\n",
    "    \"val fleuri\": \"val fleuri\",\n",
    "    \"val  fleuri\": \"val fleuri\",\n",
    "\n",
    "    \"racine\": \"racine\",\n",
    "    \"racine extension\": \"racine extension\",\n",
    "\n",
    "    \"gueliz\": \"gueliz\",\n",
    "    \"gu√©liz\": \"gueliz\",\n",
    "\n",
    "    \"agdal\": \"agdal\",\n",
    "    \"hay riad\": \"hay riad\",\n",
    "    \"souissi\": \"souissi\",\n",
    "\n",
    "    \"ain diab\": \"ain diab\",\n",
    "    \"a√Øn diab\": \"ain diab\",\n",
    "\n",
    "    \"ain sebaa\": \"ain sebaa\",\n",
    "    \"a√Øn sebaa\": \"ain sebaa\",\n",
    "\n",
    "    \"maarif\": \"maarif\",\n",
    "    \"ma√¢rif\": \"maarif\",\n",
    "    \"maarif extension\": \"maarif extension\",\n",
    "    \"ma√¢rif extension\": \"maarif extension\",\n",
    "\n",
    "    \"californie\": \"californie\",\n",
    "    \"bordeaux\": \"bordeaux\",\n",
    "\n",
    "    \"rivi√©ra\": \"riviera\",\n",
    "    \"riviera\": \"riviera\",\n",
    "\n",
    "    \"oasis\": \"oasis\",\n",
    "    \"oasis sud\": \"oasis sud\",\n",
    "\n",
    "    \"anfa\": \"anfa\",\n",
    "    \"anfa superieur\": \"anfa superieur\",\n",
    "    \"anfa sup√©rieur\": \"anfa superieur\",\n",
    "\n",
    "    \"belvedere\": \"belvedere\",\n",
    "    \"belv√©d√®re\": \"belvedere\",\n",
    "\n",
    "    \"de la plage\": \"de la plage\",\n",
    "    \"la gironde\": \"la gironde\",\n",
    "    \"hay hassani\": \"hay hassani\",\n",
    "    \"hay mohammadi\": \"hay mohammadi\",\n",
    "    \"sidi maarouf\": \"sidi maarouf\",\n",
    "    \"sidi bernoussi\": \"sidi bernoussi\",\n",
    "    \"roch es noires\": \"roches noires\",\n",
    "    \"roches noires\": \"roches noires\",\n",
    "    \"quartier des hopitaux\": \"quartier des hopitaux\",\n",
    "    \"quartier des h√¥pitaux\": \"quartier des hopitaux\",\n",
    "    \"quartier du parc\": \"quartier du parc\",\n",
    "    \"ferme bretonne (hay arraha)\": \"ferme bretonne\",\n",
    "    \"ferme bretonne\": \"ferme bretonne\",\n",
    "    \"pal mier\": \"palmier\",\n",
    "    \"palmier\": \"palmier\",\n",
    "    \"beausejour\": \"beausejour\",\n",
    "    \"beaus√©jour\": \"beausejour\",\n",
    "    \"bourn gougne\": \"bourgogne\",\n",
    "    \"bourgogne\": \"bourgogne\",\n",
    "    \"bourgogne est\": \"bourgogne est\",\n",
    "    \"bourgogne ouest\": \"bourgogne ouest\",\n",
    "    \"casablanca finance city\": \"casablanca finance city\",\n",
    "    \"cfc\": \"casablanca finance city\",\n",
    "    \"gaut hier\": \"gauthier\",\n",
    "    \"gauthier\": \"gauthier\",\n",
    "    \"triangle d'or\": \"triangle d'or\",\n",
    "\n",
    "    \"hivernage\": \"hivernage\",\n",
    "    \"ennakhil (palmeraie)\": \"ennakhil (palmeraie)\",\n",
    "    \"palmeraie\": \"palmeraie\",\n",
    "    \"targa\": \"targa\",\n",
    "    \"route de l ourika\": \"route de l'ourika\",\n",
    "    \"route d ourika\": \"route de l'ourika\",\n",
    "    \"route d'ourika\": \"route de l'ourika\",\n",
    "    \"route de l'ourika\": \"route de l'ourika\",\n",
    "    \"route de tahanaoute\": \"route de tahanaoute\",\n",
    "    \"route de fez\": \"route de fez\",\n",
    "    \"route de f√®s\": \"route de fez\",\n",
    "    \"route d amezmiz\": \"route d'amezmiz\",\n",
    "    \"route d'amezmiz\": \"route d'amezmiz\",\n",
    "    \"sem lalia\": \"semlalia\",\n",
    "    \"semlalia\": \"semlalia\",\n",
    "    \"amirich\": \"amerchich\",\n",
    "    \"amerchich\": \"amerchich\",\n",
    "    \"majorelle\": \"majorelle\",\n",
    "    \"massira\": \"massira\",\n",
    "    \"massira 1\": \"massira 1\",\n",
    "    \"massira 2\": \"massira 2\",\n",
    "    \"massira 3\": \"massira 3\",\n",
    "    \"daoudiate\": \"daoudiate\",\n",
    "    \"taghazout\": \"taghazout\",\n",
    "    \"bab doukkala\": \"bab doukkala\",\n",
    "    \"bab atlas\": \"bab atlas\",\n",
    "    \"ourika\": \"ourika\",\n",
    "\n",
    "    \"agadir founty\": \"founty\",\n",
    "    \"founty\": \"founty\",\n",
    "    \"haut founty\": \"haut founty\",\n",
    "    \"haut-founty\": \"haut founty\",\n",
    "    \"quartier administratif\": \"quartier administratif\",\n",
    "    \"talborjt\": \"talborjt\",\n",
    "    \"sonaba\": \"sonaba\",\n",
    "    \"inzegane\": \"inezgane\",\n",
    "    \"inezgane\": \"inezgane\",\n",
    "    \"beni makada lakdima\": \"beni makada lakdima\",\n",
    "    \"beni makada\": \"beni makada\",\n",
    "    \"mghar gha\": \"mghogha\",\n",
    "    \"mghogha\": \"mghogha\",\n",
    "    \"achakar\": \"achakar\",\n",
    "    \"tanger city center\": \"tanger city center\",\n",
    "    \"malabata\": \"malabata\",\n",
    "    \"marchan\": \"marchan\",\n",
    "    \"ziaten\": \"ziaten\",\n",
    "    \"casabarata\": \"casabarata\",\n",
    "    \"branes 2\": \"branes 2\",\n",
    "    \"branes kdima\": \"branes kdima\",\n",
    "    \"m'nar\": \"mnar\",\n",
    "    \"mnar\": \"mnar\",\n",
    "\n",
    "    \"hay riad extension\": \"hay riad extension\",\n",
    "    \"hassan - centre ville\": \"hassan - centre ville\",\n",
    "    \"hassan\": \"hassan\",\n",
    "    \"quartier de l ocean\": \"quartier de l'ocean\",\n",
    "    \"quartier de l'oc√©an\": \"quartier de l'ocean\",\n",
    "    \"quartier de l'ocean\": \"quartier de l'ocean\",\n",
    "    \"ouden a\": \"ouedayas\",\n",
    "    \"oudayas\": \"oudayas\",\n",
    "    \"guich oudaya\": \"guich oudaya\",\n",
    "    \"akkari\": \"aakkari\",\n",
    "    \"aakkari\": \"aakkari\",\n",
    "    \"ya coub el mansour\": \"yacoub el mansour\",\n",
    "    \"yacoub el mansour\": \"yacoub el mansour\",\n",
    "\n",
    "    \"la siesta\": \"la siesta\",\n",
    "    \"el mansouria\": \"el mansouria\",\n",
    "    \"had soualem\": \"had soualem\",\n",
    "    \"deroua\": \"deroua\",\n",
    "    \"nouaceur\": \"nouaceur\",\n",
    "    \"wifak\": \"wifak\",\n",
    "    \"wifaq\": \"wifak\",\n",
    "    \"sidi rahal chatai\": \"sidi rahal chatai\",\n",
    "    \"plage oued cherrat\": \"plage oued cherrat\",\n",
    "\n",
    "    # generic forms\n",
    "    \"ville nouvelle\": \"ville nouvelle\",\n",
    "    \"nouvelle ville\": \"ville nouvelle\",\n",
    "    \"ancienne medina\": \"ancienne medina\",\n",
    "    \"medina\": \"medina\",\n",
    "    \"m√©dina\": \"medina\",\n",
    "    \"la medina\": \"medina\",\n",
    "    \"ancienne m√©dina\": \"ancienne medina\",\n",
    "\n",
    "    # other one-offs from your list\n",
    "    \"beausite\": \"beausite\",\n",
    "    \"val d or\": \"val d'or\",\n",
    "    \"c i l\": \"cil\",\n",
    "    \"c.i.l\": \"cil\",\n",
    "    \"cil (hay salam)\": \"cil\",\n",
    "    \"hay salam\": \"hay salam\",\n",
    "    \"ain chock\": \"ain chock\",\n",
    "    \"a√Øn chock\": \"ain chock\",\n",
    "    \"sidi moumen\": \"sidi moumen\",\n",
    "    \"derb ghalef\": \"derb ghalef\",\n",
    "    \"derb omar\": \"derb omar\",\n",
    "    \"2 mars\": \"2 mars\",\n",
    "    \"hassan centre ville\": \"hassan - centre ville\",\n",
    "    \"el menzeh\": \"el menzeh\",\n",
    "    \"el mansouria\": \"el mansouria\",\n",
    "    \"el haouzia\": \"el haouzia\",\n",
    "    \"laimoune\": \"laymoune\",\n",
    "    \"laymoune\": \"laymoune\",\n",
    "    \"ain sebaa \": \"ain sebaa\",\n",
    "    \"ain sebaa extension\": \"ain sebaa\",\n",
    "    \"ain diab extension\": \"ain diab extension\",\n",
    "    \"casablanca marina\": \"casablanca marina\",\n",
    "    \"mozar t\": \"mozart\",\n",
    "    \"mozart\": \"mozart\",\n",
    "    \"rabat asfan\": \"rabat asfan\",  # keep literal since unclear\n",
    "}\n",
    "\n",
    "def _canon(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if s.lower() in NULLY:\n",
    "        return None\n",
    "\n",
    "    # fix mojibake early\n",
    "    s = _fix_mojibake(s)\n",
    "\n",
    "    # normalize punctuation/spaces\n",
    "    s = re.sub(r\"[‚Äê-‚Äì‚Äî]+\", \"-\", s)          # various dashes -> hyphen\n",
    "    s = re.sub(r\"[‚Äô']\", \"‚Äô\", s)              # unify apostrophes\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    # lower + unaccented key for alias lookup\n",
    "    key = _unaccent(s).lower()\n",
    "\n",
    "    # token-level fixes\n",
    "    for pat, rep in TOKEN_FIXES:\n",
    "        key = re.sub(pat, rep, key)\n",
    "\n",
    "    key = re.sub(r\"[-_/]+\", \" \", key)\n",
    "    key = re.sub(r\"\\s+\", \" \", key).strip()\n",
    "\n",
    "    # alias map first\n",
    "    if key in ALIASES:\n",
    "        return ALIASES[key]\n",
    "\n",
    "    # generic cleanup rules (don‚Äôt over-aggressively collapse semantics)\n",
    "    # 1) collapse double words (e.g., \"centre  ville\")\n",
    "    key = re.sub(r\"\\b(\\w+)\\s+\\1\\b\", r\"\\1\", key)\n",
    "\n",
    "    # 2) trim generic prefixes/suffixes noise around numbers like \"hay tarik 1\"\n",
    "    key = re.sub(r\"\\b0*(\\d+)\\b\", r\"\\1\", key)\n",
    "\n",
    "    # 3) stabilize \"route de xxx\"\n",
    "    key = re.sub(r\"\\broute\\s+de\\s+de\\b\", \"route de\", key)\n",
    "\n",
    "    # return canonical lowercase\n",
    "    return key or None\n",
    "\n",
    "normalize_neighborhood_udf = udf(_canon, StringType())\n",
    "\n",
    "# --- overwrite `neighborhood`\n",
    "silver = silver.withColumn(\"neighborhood\", normalize_neighborhood_udf(trim(col(\"neighborhood\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "194803ac-5301-43f4-82f3-f0116590281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+\n",
      "|neighborhood      |cnt|\n",
      "+------------------+---+\n",
      "|abouab sala       |1  |\n",
      "|agadir melloul    |1  |\n",
      "|ain attig         |1  |\n",
      "|al aaroui         |1  |\n",
      "|al amal           |1  |\n",
      "|al anbar          |1  |\n",
      "|al filline        |1  |\n",
      "|al madina aljadida|1  |\n",
      "|al mostakbal      |1  |\n",
      "|al moustakbal     |1  |\n",
      "+------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "(silver.groupBy(\"neighborhood\")\n",
    "       .agg(count(\"*\").alias(\"cnt\"))\n",
    "       .orderBy(col(\"cnt\").asc(), col(\"neighborhood\").asc())\n",
    "       .show(10, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5a206bc7-ba83-4350-aaef-cece645ff1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|site   |property_type     |count|\n",
      "+-------+------------------+-----+\n",
      "|avito  |NULL              |5    |\n",
      "|avito  |Autre Immobilier  |56   |\n",
      "|mubawab|Maisons           |75   |\n",
      "|mubawab|Local commercial  |117  |\n",
      "|avito  |Maisons           |118  |\n",
      "|mubawab|Bureaux           |125  |\n",
      "|mubawab|Terrains et fermes|194  |\n",
      "|avito  |Terrains et fermes|278  |\n",
      "|mubawab|Villas et Riads   |363  |\n",
      "|avito  |Bureaux           |364  |\n",
      "|avito  |Local             |403  |\n",
      "|avito  |Villas et Riads   |431  |\n",
      "|mubawab|Appartements      |1467 |\n",
      "|avito  |Appartements      |2336 |\n",
      "+-------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\" , \"property_type\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"count\").asc()) \\\n",
    "      .show(1000, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3347ecec-a148-4ee9-95de-3bf3b1979453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|property_type     |count|\n",
      "+------------------+-----+\n",
      "|Appartements      |3803 |\n",
      "|Villas et Riads   |794  |\n",
      "|Bureaux           |489  |\n",
      "|Terrains et fermes|472  |\n",
      "|Local             |403  |\n",
      "|Maisons           |193  |\n",
      "|Local commercial  |117  |\n",
      "|Autre Immobilier  |56   |\n",
      "|NULL              |5    |\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, trim\n",
    "from pyspark.sql.types import StringType\n",
    "import unicodedata, re\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", s)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "def normalize_property_type(value: str) -> str:\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    raw = value.strip()\n",
    "    if raw == \"\":\n",
    "        return None\n",
    "\n",
    "    s = _unaccent(raw).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # ======= mapping demand√© =======\n",
    "    # Ferme + Terrain + Terrains et fermes ‚Üí Terrains et fermes\n",
    "    if s in {\"ferme\", \"terrain\", \"terrains et fermes\"}:\n",
    "        return \"Terrains et fermes\"\n",
    "\n",
    "    # Riad + Villa + Villas et Riads ‚Üí Villas et Riads\n",
    "    if s in {\"riad\", \"villa\", \"villas et riads\"}:\n",
    "        return \"Villas et Riads\"\n",
    "\n",
    "    # Bureau + Bureaux ‚Üí Bureaux\n",
    "    if s in {\"bureau\", \"bureaux\"}:\n",
    "        return \"Bureaux\"\n",
    "\n",
    "    # Maison + Maisons ‚Üí Maisons\n",
    "    if s in {\"maison\", \"maisons\"}:\n",
    "        return \"Maisons\"\n",
    "\n",
    "    # Appartement + Appartements ‚Üí Appartements\n",
    "    if s in {\"appartement\", \"appartements\"}:\n",
    "        return \"Appartements\"\n",
    "\n",
    "    # valeurs vides / null √©quivalentes\n",
    "    if s in {\"\", \"null\", \"none\"}:\n",
    "        return None\n",
    "\n",
    "    # pour tout le reste : on garde la valeur originale trim√©e\n",
    "    return raw\n",
    "\n",
    "normalize_property_type_udf = F.udf(normalize_property_type, StringType())\n",
    "\n",
    "# üîÅ overwrite de la **m√™me** colonne dans le m√™me DataFrame\n",
    "silver = silver.withColumn(\n",
    "    \"property_type\",\n",
    "    normalize_property_type_udf(trim(col(\"property_type\")))\n",
    ")\n",
    "\n",
    "# (optionnel) v√©rifier le r√©sultat\n",
    "(\n",
    "    silver.groupBy(\"property_type\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(F.col(\"count\").desc())\n",
    "          .show(100, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5f6f6188-8140-4142-bb85-dd15bd7f6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+-----+\n",
      "|equipments                                                         |count|\n",
      "+-------------------------------------------------------------------+-----+\n",
      "|[Ascenseur, Balcon, Climatisation, Concierge, Parking]             |1    |\n",
      "|[Ascenseur, Climatisation, Cuisine √©quip√©e, Parking, S√©curit√©]     |1    |\n",
      "|[Ascenseur, Concierge, Cuisine √©quip√©e, Meubl√©, Parking]           |1    |\n",
      "|[Climatisation, Cuisine √©quip√©e, Meubl√©, Parking, S√©curit√©]        |1    |\n",
      "|[Duplex, Climatisation, Cuisine √©quip√©e, S√©curit√©, Terrasse]       |1    |\n",
      "|[Balcon, Cuisine √©quip√©e, Meubl√©]                                  |1    |\n",
      "|[Ascenseur, Chauffage, Climatisation, Concierge, Parking, Terrasse]|1    |\n",
      "|[Ascenseur, Balcon, Cuisine √©quip√©e, Meubl√©, Parking, S√©curit√©]    |1    |\n",
      "|[Ascenseur, Balcon, Concierge, Meubl√©, Parking, Terrasse]          |1    |\n",
      "|[Ascenseur, Balcon, Cuisine √©quip√©e]                               |1    |\n",
      "+-------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"equipments\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1ed0246d-931b-4c28-bb78-5e5acc4c961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NORMALIZE `equipments` IN-PLACE (silver DataFrame) ---\n",
    "\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import re, unicodedata\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# 1) Canonical vocabulary you want to keep inside `equipments`\n",
    "CANON = {\n",
    "    # √©tat / disponibilit√© / standing / type / foncier\n",
    "    \"neuf\",\"bon_etat\",\"a_renover\",\"livraison_immediate\",\n",
    "    \"economique\",\"moyen_standing\",\"haut_standing\",\n",
    "    \"duplex\",\"maison\",\"villa\",\"immeuble\",\n",
    "    \"loti\",\"titre_foncier\",\"agricole\",\"industriel\",\"service_public\",\n",
    "\n",
    "    # √©quipements / ext√©rieurs / gestion\n",
    "    \"ascenseur\",\"balcon\",\"terrasse\",\"jardin\",\"garage\",\"parking\",\"piscine\",\n",
    "    \"climatisation\",\"chauffage\",\"cuisine_equipee\",\"meuble\",\n",
    "    \"securite\",\"concierge\",\"cablage_telephonique\",\n",
    "}\n",
    "\n",
    "# 2) Synonyms / variants ‚Üí canonical\n",
    "SYNONYMS = {\n",
    "    # √©tat\n",
    "    \"bon etat\":\"bon_etat\",\"etat correct\":\"bon_etat\",\"etat-bon\":\"bon_etat\",\n",
    "    \"a renover\":\"a_renover\",\"√† renover\":\"a_renover\",\"√† r√©nover\":\"a_renover\",\n",
    "    # disponibilit√©\n",
    "    \"immediate\":\"livraison_immediate\",\"imm√©diate\":\"livraison_immediate\",\"livraison immediate\":\"livraison_immediate\",\n",
    "    # standing\n",
    "    \"standing moyen\":\"moyen_standing\",\"moyen-standing\":\"moyen_standing\",\"moyen standing\":\"moyen_standing\",\n",
    "    \"haut standing\":\"haut_standing\",\"tres haut standing\":\"haut_standing\",\"tr√®s haut standing\":\"haut_standing\",\n",
    "    # type\n",
    "    \"appartement duplex\":\"duplex\",\"duplexe\":\"duplex\",\n",
    "    # foncier / zonage / titre\n",
    "    \"titre\":\"titre_foncier\",\"titr√©\":\"titre_foncier\",\"titre foncier\":\"titre_foncier\",\n",
    "    \"lotis\":\"loti\",\"lotissement\":\"loti\",\n",
    "    \"agricole\":\"agricole\",\"industriel\":\"industriel\",\"service public\":\"service_public\",\n",
    "    # √©quipements\n",
    "    \"clim\":\"climatisation\",\"climatisations\":\"climatisation\",\n",
    "    \"chauffages\":\"chauffage\",\n",
    "    \"cuisine equipee\":\"cuisine_equipee\",\"cuisine equip√©e\":\"cuisine_equipee\",\"cuisine √©quip√©e\":\"cuisine_equipee\",\n",
    "    \"meuble\":\"meuble\",\"meubl√©\":\"meuble\",\"meublee\":\"meuble\",\n",
    "    \"securite\":\"securite\",\"s√©curit√©\":\"securite\",\n",
    "    \"concierge\":\"concierge\",\n",
    "    \"cablage telephonique\":\"cablage_telephonique\",\"c√¢blage telephonique\":\"cablage_telephonique\",\"c√¢blage t√©l√©phonique\":\"cablage_telephonique\",\n",
    "    \"ascenseur\":\"ascenseur\",\"ascenseurs\":\"ascenseur\",\n",
    "    \"balcon\":\"balcon\",\"balcons\":\"balcon\",\n",
    "    \"terrasse\":\"terrasse\",\"terrasses\":\"terrasse\",\n",
    "    \"jardin\":\"jardin\",\"jardins\":\"jardin\",\n",
    "    \"garage\":\"garage\",\"garages\":\"garage\",\n",
    "    \"parking\":\"parking\",\"parkings\":\"parking\",\n",
    "    \"piscine\":\"piscine\",\"piscines\":\"piscine\",\n",
    "    # types de bien courants dans tes donn√©es\n",
    "    \"maison\":\"maison\",\"villa\":\"villa\",\"immeuble\":\"immeuble\",\n",
    "    # autres graphies fr√©quentes vues\n",
    "    \"economique\":\"economique\",\"moyen standing\":\"moyen_standing\",\"haut-standing\":\"haut_standing\",\n",
    "}\n",
    "\n",
    "# 3) helpers\n",
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
    "\n",
    "def _clean_token(t: str) -> str:\n",
    "    t = _strip_accents(t or \"\").lower()\n",
    "    t = re.sub(r\"[,_/|;+]\", \" \", t)        # unify separators\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# Optional: lightweight fuzzy match using plain Python Levenshtein\n",
    "# (fast enough for short token lists; keeps your single-column constraint)\n",
    "def _levenshtein(a: str, b: str) -> int:\n",
    "    if a == b: return 0\n",
    "    if not a: return len(b)\n",
    "    if not b: return len(a)\n",
    "    prev = list(range(len(b)+1))\n",
    "    for i, ca in enumerate(a, 1):\n",
    "        cur = [i]\n",
    "        for j, cb in enumerate(b, 1):\n",
    "            ins = cur[j-1] + 1\n",
    "            dele = prev[j] + 1\n",
    "            sub = prev[j-1] + (ca != cb)\n",
    "            cur.append(min(ins, dele, sub))\n",
    "        prev = cur\n",
    "    return prev[-1]\n",
    "\n",
    "def _to_canonical(tok: str) -> Optional[str]:\n",
    "    if not tok:\n",
    "        return None\n",
    "    # exact map via synonyms\n",
    "    if tok in SYNONYMS:\n",
    "        return SYNONYMS[tok]\n",
    "    # already canonical?\n",
    "    if tok in CANON:\n",
    "        return tok\n",
    "    # try joining words with underscore if looks like \"cuisine equipee\"\n",
    "    tok_und = tok.replace(\" \", \"_\")\n",
    "    if tok_und in CANON: \n",
    "        return tok_und\n",
    "    # fuzzy to nearest canonical if very close (typos)\n",
    "    # threshold: <=1 for short tokens, <=2 otherwise\n",
    "    best = None\n",
    "    best_d = 10**9\n",
    "    for c in CANON:\n",
    "        d = _levenshtein(tok_und, c)\n",
    "        if d < best_d:\n",
    "            best, best_d = c, d\n",
    "    if best is not None:\n",
    "        thr = 1 if len(tok_und) <= 6 else 2\n",
    "        if best_d <= thr:\n",
    "            return best\n",
    "    return None  # drop unknowns (stays within same column contract)\n",
    "\n",
    "@udf(ArrayType(StringType()))\n",
    "def normalize_equipments(arr):\n",
    "    # Accept array<string> or a single string (comma/semicolon separated)\n",
    "    if arr is None:\n",
    "        return None  # preserve NULL as NULL (distinct from [])\n",
    "    tokens = []\n",
    "    if isinstance(arr, list):\n",
    "        for x in arr:\n",
    "            if x is None: \n",
    "                continue\n",
    "            # some inputs can be \"A, B, C\" inside a single element\n",
    "            parts = re.split(r\"[;,]\", str(x))\n",
    "            tokens.extend(parts)\n",
    "    else:\n",
    "        tokens = re.split(r\"[;,]\", str(arr))\n",
    "\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for t in tokens:\n",
    "        t = _clean_token(t)\n",
    "        if not t:\n",
    "            continue\n",
    "        can = _to_canonical(t)\n",
    "        if can and can not in seen:\n",
    "            seen.add(can)\n",
    "            out.append(can)\n",
    "\n",
    "    # stable order: alphabetical for determinism\n",
    "    out.sort()\n",
    "    return out\n",
    "\n",
    "# 4) apply in-place on silver\n",
    "silver = silver.withColumn(\"equipments\", normalize_equipments(col(\"equipments\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ab3373f6-cfcd-46cf-a9d0-717f28fa12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------+-----+\n",
      "|site   |surface_habitable|surface_totale|count|\n",
      "+-------+-----------------+--------------+-----+\n",
      "|mubawab|NULL             |NULL          |2341 |\n",
      "|avito  |25               |NULL          |1    |\n",
      "|avito  |NULL             |29            |1    |\n",
      "|avito  |118              |NULL          |1    |\n",
      "|avito  |214              |NULL          |1    |\n",
      "|avito  |120              |160           |1    |\n",
      "|avito  |160              |160           |1    |\n",
      "|avito  |50               |55            |1    |\n",
      "|avito  |300              |500           |1    |\n",
      "|avito  |88               |NULL          |1    |\n",
      "+-------+-----------------+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"surface_habitable\" , \"surface_totale\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").desc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "30d030ce-c521-4037-8d7a-9bbfb501b57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "|site   |surface_totale|count|\n",
      "+-------+--------------+-----+\n",
      "|mubawab|NULL          |2341 |\n",
      "|avito  |2800          |1    |\n",
      "|avito  |198           |1    |\n",
      "|avito  |1400          |1    |\n",
      "|avito  |2343          |1    |\n",
      "|avito  |165           |1    |\n",
      "|avito  |790000        |1    |\n",
      "|avito  |426           |1    |\n",
      "|avito  |123           |1    |\n",
      "|avito  |29            |1    |\n",
      "+-------+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"surface_totale\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").desc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "77d58f65-3b6e-4f34-b02f-3030850dd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, regexp_replace, trim\n",
    "\n",
    "# 1) Nettoyer/typer surface_de_la_parcelle (souvent \"520 m¬≤\", espaces, NBSP, etc.)\n",
    "# - enl√®ve tout sauf chiffres . et ,\n",
    "# - remplace virgule par point\n",
    "# - cast en double\n",
    "parcelle_clean = (\n",
    "    regexp_replace(trim(col(\"surface_de_la_parcelle\")), r\"\\u00A0\", \" \")       # NBSP -> espace\n",
    ")\n",
    "parcelle_clean = regexp_replace(parcelle_clean, r\"[^0-9\\.,]\", \"\")             # garder chiffres . ,\n",
    "parcelle_clean = regexp_replace(parcelle_clean, r\",\", \".\")                    # virgule -> point\n",
    "parcelle_clean = parcelle_clean.cast(\"double\")\n",
    "\n",
    "silver = silver.withColumn(\"surface_de_la_parcelle\", parcelle_clean)\n",
    "\n",
    "# 2) Overwrite de surface_totale avec parcelle quand surface_totale est NULL et parcelle NON NULL/positive\n",
    "silver = silver.withColumn(\n",
    "    \"surface_totale\",\n",
    "    when(\n",
    "        col(\"surface_totale\").isNull() & col(\"surface_de_la_parcelle\").isNotNull() & (col(\"surface_de_la_parcelle\") > 0),\n",
    "        col(\"surface_de_la_parcelle\")\n",
    "    ).otherwise(col(\"surface_totale\"))\n",
    ")\n",
    "\n",
    "# 3) Drop d√©finitif de surface_de_la_parcelle\n",
    "silver = silver.drop(\"surface_de_la_parcelle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01bae0f7-2e7c-44b0-825d-3ad0bbe6fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lower, regexp_replace, trim, coalesce\n",
    "\n",
    "# helpers\n",
    "def _num(colname):\n",
    "    # strip NBSP, keep digits/., replace comma, cast\n",
    "    c = regexp_replace(trim(col(colname)), r\"\\u00A0\", \" \")\n",
    "    c = regexp_replace(c, r\"[^0-9\\.,]\", \"\")\n",
    "    c = regexp_replace(c, r\",\", \".\").cast(\"double\")\n",
    "    return when(c <= 0, None).otherwise(c)\n",
    "\n",
    "# A) parse\n",
    "silver = silver.withColumn(\"surface_totale\", _num(\"surface_totale\")) \\\n",
    "               .withColumn(\"surface_habitable\", _num(\"surface_habitable\"))\n",
    "\n",
    "# C) type buckets\n",
    "pt = lower(coalesce(col(\"property_type\"), col(\"type_de_bien\")))\n",
    "\n",
    "is_land   = pt.rlike(r\"(terrain|ferme|terrains|loti|lot|agricole)\")\n",
    "is_appt   = pt.rlike(r\"(appart|studio|duplex)\")\n",
    "is_house  = pt.rlike(r\"(maison|villa|riad)\")\n",
    "is_office = pt.rlike(r\"(bureau|local)\")\n",
    "\n",
    "def keep_between(c, lo, hi): \n",
    "    return when((c >= lo) & (c <= hi), c)\n",
    "\n",
    "# Copy for editing\n",
    "ST = col(\"surface_totale\")\n",
    "SH = col(\"surface_habitable\")\n",
    "\n",
    "# Appartements\n",
    "ST_appt = keep_between(ST, 15, 1500)\n",
    "SH_appt = keep_between(SH, 10, 1200)\n",
    "\n",
    "# Maisons/Villas\n",
    "ST_house = keep_between(ST, 30, 50000)\n",
    "SH_house = keep_between(SH, 20, 2000)\n",
    "\n",
    "# Bureaux/Locaux\n",
    "ST_off   = keep_between(ST, 10, 50000)\n",
    "SH_off   = keep_between(SH, 10, 10000)\n",
    "\n",
    "# Terrains\n",
    "ST_land = keep_between(ST, 10, 1_000_000)\n",
    "# land habitable should be null\n",
    "SH_land = None\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"surface_totale\",\n",
    "    when(is_appt, ST_appt)\n",
    "    .when(is_house, ST_house)\n",
    "    .when(is_office, ST_off)\n",
    "    .when(is_land, ST_land)\n",
    "    .otherwise(keep_between(ST, 10, 200000))  # fallback conservative\n",
    ")\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"surface_habitable\",\n",
    "    when(is_appt, SH_appt)\n",
    "    .when(is_house, SH_house)\n",
    "    .when(is_office, SH_off)\n",
    "    .when(is_land, None)  # drop habitable on land\n",
    "    .otherwise(keep_between(SH, 10, 5000))\n",
    ")\n",
    "\n",
    "# D) swap if obviously inverted\n",
    "ST = col(\"surface_totale\"); SH = col(\"surface_habitable\")\n",
    "swap_cond = (ST.isNotNull() & SH.isNotNull() &\n",
    "             (SH >= 2*ST) &\n",
    "             ((ST <= 400) | (SH / ST >= 5))\n",
    "            )\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"surface_totale\",\n",
    "    when(swap_cond, SH).otherwise(col(\"surface_totale\"))\n",
    ").withColumn(\n",
    "    \"surface_habitable\",\n",
    "    when(swap_cond, ST).otherwise(col(\"surface_habitable\"))\n",
    ")\n",
    "\n",
    "# E) enforce relationship for non-land\n",
    "ST = col(\"surface_totale\"); SH = col(\"surface_habitable\")\n",
    "too_big = (SH > ST) & (~is_land)\n",
    "silver = silver.withColumn(\n",
    "    \"surface_habitable\",\n",
    "    when(too_big & (SH <= 1.2*ST), SH)  # keep small overshoot\n",
    "    .when(too_big, None)\n",
    "    .otherwise(SH)\n",
    ")\n",
    "\n",
    "# F) de-spike small integers\n",
    "def null_small_nonland(c): \n",
    "    return when((~is_land) & (c < 10), None).otherwise(c)\n",
    "\n",
    "silver = silver.withColumn(\"surface_totale\",   null_small_nonland(col(\"surface_totale\")))\n",
    "silver = silver.withColumn(\"surface_habitable\",null_small_nonland(col(\"surface_habitable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3069154c-33b4-4e77-acc0-c9f5228aa56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+---------------+------------------------------------+\n",
      "|site   |nn_property_type|nn_type_de_bien|fill_property_type_from_type_de_bien|\n",
      "+-------+----------------+---------------+------------------------------------+\n",
      "|mubawab|4853            |4853           |0                                   |\n",
      "|avito  |5322            |0              |0                                   |\n",
      "+-------+----------------+---------------+------------------------------------+\n",
      "\n",
      "+-------+-------+------------+------------------------+\n",
      "|site   |nn_etat|nn_condition|fill_etat_from_condition|\n",
      "+-------+-------+------------+------------------------+\n",
      "|mubawab|4508   |0           |0                       |\n",
      "|avito  |0      |2001        |2001                    |\n",
      "+-------+-------+------------+------------------------+\n",
      "\n",
      "+-------+--------+----------------+-----------------------------+\n",
      "|site   |nn_etage|nn_etage_du_bien|fill_etage_from_etage_du_bien|\n",
      "+-------+--------+----------------+-----------------------------+\n",
      "|mubawab|0       |2938            |2938                         |\n",
      "|avito  |1080    |0               |0                            |\n",
      "+-------+--------+----------------+-----------------------------+\n",
      "\n",
      "+-------+-------------+--------------------------+--------------------------------------------+\n",
      "|site   |nn_equipments|nn_features_amenities_json|fill_equipments_from_features_amenities_json|\n",
      "+-------+-------------+--------------------------+--------------------------------------------+\n",
      "|mubawab|0            |4698                      |4698                                        |\n",
      "|avito  |5339         |0                         |0                                           |\n",
      "+-------+-------------+--------------------------+--------------------------------------------+\n",
      "\n",
      "+-------+---------+--------------+----------------------------+\n",
      "|site   |nn_annees|nn_age_du_bien|fill_annees_from_age_du_bien|\n",
      "+-------+---------+--------------+----------------------------+\n",
      "|mubawab|2810     |0             |0                           |\n",
      "|avito  |0        |326           |326                         |\n",
      "+-------+---------+--------------+----------------------------+\n",
      "\n",
      "+-------+---------+--------------+----------------------------+\n",
      "|site   |nn_zoning|nn_type_du_sol|fill_zoning_from_type_du_sol|\n",
      "+-------+---------+--------------+----------------------------+\n",
      "|mubawab|0        |2456          |2456                        |\n",
      "|avito  |634      |0             |0                           |\n",
      "+-------+---------+--------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as Fsum, when\n",
    "\n",
    "pairs = [\n",
    "  (\"property_type\",\"type_de_bien\"),\n",
    "  (\"etat\",\"condition\"),\n",
    "  (\"etage\",\"etage_du_bien\"),\n",
    "  (\"equipments\",\"features_amenities_json\"),\n",
    "  (\"annees\",\"age_du_bien\"),\n",
    "  (\"zoning\",\"type_du_sol\"),\n",
    "]\n",
    "\n",
    "for a,b in pairs:\n",
    "    silver.groupBy(\"site\").agg(\n",
    "        Fsum(when(col(a).isNotNull(),1).otherwise(0)).alias(f\"nn_{a}\"),\n",
    "        Fsum(when(col(b).isNotNull(),1).otherwise(0)).alias(f\"nn_{b}\"),\n",
    "        Fsum(when(col(a).isNull() & col(b).isNotNull(),1).otherwise(0)).alias(f\"fill_{a}_from_{b}\"),\n",
    "    ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d4a02761-bf34-4ace-a04f-d634c67ea79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+-----+\n",
      "|site   |property_type     |type_de_bien    |count|\n",
      "+-------+------------------+----------------+-----+\n",
      "|mubawab|Terrains et fermes|Ferme           |5    |\n",
      "|mubawab|Villas et Riads   |Riad            |44   |\n",
      "|mubawab|Maisons           |Maison          |75   |\n",
      "|mubawab|Local commercial  |Local commercial|117  |\n",
      "|mubawab|Bureaux           |Bureau          |125  |\n",
      "|mubawab|Terrains et fermes|Terrain         |189  |\n",
      "|mubawab|Villas et Riads   |Villa           |319  |\n",
      "|mubawab|Appartements      |Appartement     |1467 |\n",
      "|avito  |NULL              |NULL            |5    |\n",
      "|avito  |Autre Immobilier  |NULL            |56   |\n",
      "+-------+------------------+----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"property_type\" , \"type_de_bien\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").desc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8919c9-f011-435b-b079-a53b86f39de4",
   "metadata": {},
   "source": [
    "## condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "335d8e4b-5edf-453c-95b5-15e2fdcc746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+\n",
      "|site   |etat     |count|\n",
      "+-------+---------+-----+\n",
      "|avito  |NULL     |3991 |\n",
      "|mubawab|√Ä r√©nover|60   |\n",
      "|mubawab|NULL     |291  |\n",
      "|mubawab|Nouveau  |806  |\n",
      "|mubawab|Bon √©tat |1184 |\n",
      "+-------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"etat\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0267fa1b-cf61-4e0e-8009-1fc7cf7342bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "|site   |standing      |count|\n",
      "+-------+--------------+-----+\n",
      "|avito  |Economique    |30   |\n",
      "|avito  |Moyen standing|70   |\n",
      "|avito  |Haut standing |90   |\n",
      "|avito  |NULL          |3801 |\n",
      "|mubawab|NULL          |2341 |\n",
      "+-------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"standing\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "66ec1b11-5470-4049-8013-523e22058a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+\n",
      "|site   |condition|count|\n",
      "+-------+---------+-----+\n",
      "|avito  |√† r√©nover|32   |\n",
      "|avito  |Bon √©tat |344  |\n",
      "|avito  |Neuf     |561  |\n",
      "|avito  |NULL     |3054 |\n",
      "|mubawab|NULL     |2341 |\n",
      "+-------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"condition\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c5fc9b3a-a6e7-40a5-874a-84ad307a100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop useless 'standing' column ---\n",
    "if \"standing\" in silver.columns:\n",
    "    silver = silver.drop(\"standing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a464a21-287e-4fd5-99e3-ee95140628d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "|site   |condition     |count|\n",
      "+-------+--------------+-----+\n",
      "|avito  |To renovate   |32   |\n",
      "|avito  |Good condition|344  |\n",
      "|avito  |New           |561  |\n",
      "|avito  |NULL          |3054 |\n",
      "|mubawab|To renovate   |60   |\n",
      "|mubawab|NULL          |291  |\n",
      "|mubawab|New           |806  |\n",
      "|mubawab|Good condition|1184 |\n",
      "+-------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, coalesce, trim\n",
    "from pyspark.sql.types import StringType\n",
    "import unicodedata, re\n",
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", s)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "def normalize_condition(v: str) -> str:\n",
    "    if v is None:\n",
    "        return None\n",
    "\n",
    "    raw = v.strip()\n",
    "    if raw == \"\":\n",
    "        return None\n",
    "\n",
    "    s = _unaccent(raw).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # ---- mapping ‚Üí ENGLISH ----\n",
    "    # Bon √©tat ‚Üí Good condition\n",
    "    if s in {\"bon etat\", \"bon √©tat\"}:\n",
    "        return \"Good condition\"\n",
    "\n",
    "    # Neuf / Nouveau ‚Üí New\n",
    "    if s in {\"neuf\", \"nouveau\"}:\n",
    "        return \"New\"\n",
    "\n",
    "    # √Ä r√©nover ‚Üí To renovate\n",
    "    if s in {\"a renover\", \"√† renover\", \"a r√©nover\", \"√† r√©nover\"}:\n",
    "        return \"To renovate\"\n",
    "\n",
    "    # empty / null-like\n",
    "    if s in {\"\", \"null\", \"none\"}:\n",
    "        return None\n",
    "\n",
    "    # fallback: capitalized original (just in case new values appear)\n",
    "    return raw.capitalize()\n",
    "\n",
    "normalize_condition_udf = F.udf(normalize_condition, StringType())\n",
    "\n",
    "# ---------- apply merge + normalization ----------\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"condition\",\n",
    "    normalize_condition_udf(\n",
    "        trim(coalesce(col(\"condition\"), col(\"etat\")))\n",
    "    )\n",
    ")\n",
    "\n",
    "# drop etat, we don't need it anymore\n",
    "if \"etat\" in silver.columns:\n",
    "    silver = silver.drop(\"etat\")\n",
    "\n",
    "# ---------- sanity check ----------\n",
    "\n",
    "(\n",
    "    silver.groupBy(\"site\", \"condition\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(col(\"site\").asc(), col(\"count\").asc())\n",
    "          .show(50, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a94b1a-7afa-4cb5-bfc5-9de0eac368c4",
   "metadata": {},
   "source": [
    "## etage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "38b22e16-a196-48ec-b271-77a31cbbf650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|site   |etage|count|\n",
      "+-------+-----+-----+\n",
      "|avito  |11   |1    |\n",
      "|avito  |16   |2    |\n",
      "|avito  |9    |2    |\n",
      "|avito  |15   |3    |\n",
      "|avito  |10   |7    |\n",
      "|avito  |8    |8    |\n",
      "|avito  |6    |27   |\n",
      "|avito  |7    |28   |\n",
      "|avito  |5    |73   |\n",
      "|avito  |4    |128  |\n",
      "|avito  |0    |154  |\n",
      "|avito  |3    |175  |\n",
      "|avito  |2    |257  |\n",
      "|avito  |1    |339  |\n",
      "|avito  |NULL |2787 |\n",
      "|mubawab|NULL |2341 |\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"etage\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "abe6f77e-6d10-4bbe-9722-99b6d184286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+\n",
      "|site   |etage_du_bien|count|\n",
      "+-------+-------------+-----+\n",
      "|avito  |NULL         |3991 |\n",
      "|mubawab|13√®me        |1    |\n",
      "|mubawab|15√®me        |1    |\n",
      "|mubawab|18√®me        |2    |\n",
      "|mubawab|9√®me         |6    |\n",
      "|mubawab|10√®me        |6    |\n",
      "|mubawab|8√®me         |8    |\n",
      "|mubawab|7√®me         |18   |\n",
      "|mubawab|6√®me         |22   |\n",
      "|mubawab|5√®me         |76   |\n",
      "|mubawab|4√®me         |145  |\n",
      "|mubawab|1er          |217  |\n",
      "|mubawab|3√®me         |246  |\n",
      "|mubawab|2√®me         |250  |\n",
      "|mubawab|NULL         |1343 |\n",
      "+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"etage_du_bien\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba28a85d-073f-4975-a2f1-2409485e8682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|site   |etage|count|\n",
      "+-------+-----+-----+\n",
      "|avito  |11   |1    |\n",
      "|avito  |9    |2    |\n",
      "|avito  |16   |2    |\n",
      "|avito  |15   |3    |\n",
      "|avito  |10   |7    |\n",
      "|avito  |8    |8    |\n",
      "|avito  |6    |27   |\n",
      "|avito  |7    |28   |\n",
      "|avito  |5    |73   |\n",
      "|avito  |4    |128  |\n",
      "|avito  |0    |154  |\n",
      "|avito  |3    |175  |\n",
      "|avito  |2    |257  |\n",
      "|avito  |1    |339  |\n",
      "|avito  |NULL |2787 |\n",
      "|mubawab|13   |1    |\n",
      "|mubawab|15   |1    |\n",
      "|mubawab|18   |2    |\n",
      "|mubawab|10   |6    |\n",
      "|mubawab|9    |6    |\n",
      "|mubawab|8    |8    |\n",
      "|mubawab|7    |18   |\n",
      "|mubawab|6    |22   |\n",
      "|mubawab|5    |76   |\n",
      "|mubawab|4    |145  |\n",
      "|mubawab|1    |217  |\n",
      "|mubawab|3    |246  |\n",
      "|mubawab|2    |250  |\n",
      "|mubawab|NULL |1343 |\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, trim, coalesce\n",
    "from pyspark.sql.types import StringType\n",
    "import unicodedata, re\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", s)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "def normalize_floor(etage_val: str, etage_bien_val: str) -> str:\n",
    "    \"\"\"\n",
    "    Retourne un √©tage normalis√© sous forme de string num√©rique (\"0\",\"1\",\"2\",...) ou None.\n",
    "    Priorit√© : etage (Avito) puis etage_du_bien (Mubawab).\n",
    "    \"\"\"\n",
    "    # 1) essayer d'utiliser etage (Avito)\n",
    "    if etage_val is not None:\n",
    "        raw = etage_val.strip()\n",
    "        if raw != \"\":\n",
    "            # si c'est d√©j√† un nombre propre, on le garde\n",
    "            if re.fullmatch(r\"\\d+\", raw):\n",
    "                return str(int(raw))  # normaliser genre \"01\" -> \"1\"\n",
    "            # sinon on tente d'extraire des chiffres quand m√™me\n",
    "            m = re.search(r\"\\d+\", raw)\n",
    "            if m:\n",
    "                return str(int(m.group(0)))\n",
    "\n",
    "    # 2) fallback : etage_du_bien (Mubawab, ex: \"3√®me\", \"1er\", \"10√®me\")\n",
    "    if etage_bien_val is not None:\n",
    "        raw2 = etage_bien_val.strip()\n",
    "        if raw2 != \"\":\n",
    "            s = _unaccent(raw2).lower()\n",
    "            s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "            # cas \"RDC\" possibles (au cas o√π √ßa arrive un jour)\n",
    "            if s in {\"rdc\", \"rez de chaussee\", \"rez-de-chaussee\"}:\n",
    "                return \"0\"\n",
    "\n",
    "            # extraire le premier nombre qui passe (1er, 2eme, 3eme, 10eme, 18eme‚Ä¶)\n",
    "            m2 = re.search(r\"\\d+\", s)\n",
    "            if m2:\n",
    "                return str(int(m2.group(0)))\n",
    "\n",
    "    # 3) sinon : rien\n",
    "    return None\n",
    "\n",
    "normalize_floor_udf = F.udf(normalize_floor, StringType())\n",
    "\n",
    "# --------- appliquer fusion + normalisation ---------\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"etage\",\n",
    "    normalize_floor_udf(\n",
    "        trim(col(\"etage\")),\n",
    "        trim(col(\"etage_du_bien\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# on n'a plus besoin d'etage_du_bien\n",
    "if \"etage_du_bien\" in silver.columns:\n",
    "    silver = silver.drop(\"etage_du_bien\")\n",
    "\n",
    "# --------- sanity check ---------\n",
    "(\n",
    "    silver.groupBy(\"site\", \"etage\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(col(\"site\").asc(), col(\"count\").asc())\n",
    "          .show(100, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eef78f-84b7-4260-9e11-8ac780d05e11",
   "metadata": {},
   "source": [
    "## nombre_d_etage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e7fc438d-e58f-4e39-b3be-6084ef5b2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "|site   |nombre_d_etage|count|\n",
      "+-------+--------------+-----+\n",
      "|avito  |4             |3    |\n",
      "|avito  |3             |99   |\n",
      "|avito  |2             |116  |\n",
      "|avito  |1             |141  |\n",
      "|avito  |NULL          |3632 |\n",
      "|mubawab|NULL          |2341 |\n",
      "+-------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"nombre_d_etage\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "15008b44-4840-4686-93a2-9bcca8b761c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----+\n",
      "|site   |nombre_d_etages|count|\n",
      "+-------+---------------+-----+\n",
      "|avito  |NULL           |3991 |\n",
      "|mubawab|4              |11   |\n",
      "|mubawab|3              |71   |\n",
      "|mubawab|2              |89   |\n",
      "|mubawab|1              |95   |\n",
      "|mubawab|NULL           |2075 |\n",
      "+-------+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"nombre_d_etages\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8367618c-ebe2-4f8a-b925-4f5d67c9af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----+\n",
      "|site   |nombre_d_etages|count|\n",
      "+-------+---------------+-----+\n",
      "|avito  |4              |3    |\n",
      "|avito  |3              |99   |\n",
      "|avito  |2              |116  |\n",
      "|avito  |1              |141  |\n",
      "|avito  |NULL           |3632 |\n",
      "|mubawab|4              |11   |\n",
      "|mubawab|3              |71   |\n",
      "|mubawab|2              |89   |\n",
      "|mubawab|1              |95   |\n",
      "|mubawab|NULL           |2075 |\n",
      "+-------+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, trim\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "\n",
    "def normalize_nb_floors(v1: str, v2: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalise le nombre d'√©tages en cha√Æne num√©rique (\"1\",\"2\",...)\n",
    "    Priorit√©: v1 = nombre_d_etage (Avito), sinon v2 = nombre_d_etages (Mubawab).\n",
    "    \"\"\"\n",
    "    # helper interne\n",
    "    def _parse_num(x: str):\n",
    "        if x is None:\n",
    "            return None\n",
    "        raw = x.strip()\n",
    "        if raw == \"\":\n",
    "            return None\n",
    "        # si d√©j√† un entier propre\n",
    "        if re.fullmatch(r\"\\d+\", raw):\n",
    "            return str(int(raw))\n",
    "        # sinon on tente au moins d'extraire des chiffres\n",
    "        m = re.search(r\"\\d+\", raw)\n",
    "        if m:\n",
    "            return str(int(m.group(0)))\n",
    "        return None\n",
    "\n",
    "    # 1) essayer Avito\n",
    "    n1 = _parse_num(v1)\n",
    "    if n1 is not None:\n",
    "        return n1\n",
    "\n",
    "    # 2) fallback Mubawab\n",
    "    n2 = _parse_num(v2)\n",
    "    if n2 is not None:\n",
    "        return n2\n",
    "\n",
    "    # 3) rien\n",
    "    return None\n",
    "\n",
    "normalize_nb_floors_udf = F.udf(normalize_nb_floors, StringType())\n",
    "\n",
    "# --------- appliquer fusion + normalisation ---------\n",
    "\n",
    "silver = silver.withColumn(\n",
    "    \"nombre_d_etages\",\n",
    "    normalize_nb_floors_udf(\n",
    "        trim(col(\"nombre_d_etage\")),\n",
    "        trim(col(\"nombre_d_etages\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# on n'a plus besoin de la colonne Avito brute\n",
    "if \"nombre_d_etage\" in silver.columns:\n",
    "    silver = silver.drop(\"nombre_d_etage\")\n",
    "\n",
    "# --------- sanity check ---------\n",
    "\n",
    "(\n",
    "    silver.groupBy(\"site\", \"nombre_d_etages\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(col(\"site\").asc(), col(\"count\").asc())\n",
    "          .show(100, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b04d6d-3445-4993-b77a-cd97fcb37daa",
   "metadata": {},
   "source": [
    "## type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "87b383cb-c719-4f2a-9e2c-f640e17edbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+-----+\n",
      "|site   |type_d_appartement|type_de_bien    |count|\n",
      "+-------+------------------+----------------+-----+\n",
      "|avito  |Duplex            |NULL            |41   |\n",
      "|avito  |Studio            |NULL            |121  |\n",
      "|avito  |NULL              |NULL            |3829 |\n",
      "|mubawab|NULL              |Ferme           |5    |\n",
      "|mubawab|NULL              |Riad            |44   |\n",
      "|mubawab|NULL              |Maison          |75   |\n",
      "|mubawab|NULL              |Local commercial|117  |\n",
      "|mubawab|NULL              |Bureau          |125  |\n",
      "|mubawab|NULL              |Terrain         |189  |\n",
      "|mubawab|NULL              |Villa           |319  |\n",
      "|mubawab|NULL              |Appartement     |1467 |\n",
      "+-------+------------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"type_d_appartement\" , \"type_de_bien\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb4400c-a748-41b0-aa2b-f6b99e2eb7b2",
   "metadata": {},
   "source": [
    "## terrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3f633a7-329a-4754-a9a4-3e35b9d49ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------+-----+\n",
      "|site   |type_de_terrain                                               |count|\n",
      "+-------+--------------------------------------------------------------+-----+\n",
      "|avito  |NULL                                                          |278  |\n",
      "|mubawab|Groupement d'habitation, Lots de villa                        |1    |\n",
      "|mubawab|Commercial, Groupement d'habitation, Industriel, Lots de villa|1    |\n",
      "|mubawab|Agricole, Commercial, Lots de villa                           |1    |\n",
      "|mubawab|Agricole, Commercial, Industriel                              |2    |\n",
      "|mubawab|Agricole, Groupement d'habitation, Commercial, Lots de villa  |2    |\n",
      "|mubawab|Groupement d'habitation, Lots de villa, Agricole              |2    |\n",
      "|mubawab|Commercial, Industriel                                        |2    |\n",
      "|mubawab|Agricole, Groupement d'habitation, Lots de villa              |2    |\n",
      "|mubawab|Industriel                                                    |3    |\n",
      "|mubawab|Commercial, Groupement d'habitation, Lots de villa            |3    |\n",
      "|mubawab|Groupement d'habitation, Commercial                           |4    |\n",
      "|mubawab|Commercial, Groupement d'habitation                           |13   |\n",
      "|mubawab|NULL                                                          |16   |\n",
      "|mubawab|Agricole                                                      |22   |\n",
      "|mubawab|Commercial                                                    |26   |\n",
      "|mubawab|Groupement d'habitation                                       |39   |\n",
      "|mubawab|Lots de villa                                                 |55   |\n",
      "+-------+--------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.filter(col(\"property_type\") == \"Terrains et fermes\") \\\n",
    "      .groupBy(\"site\", \"type_de_terrain\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c05037d8-45be-4fa2-9f8f-adf415a2b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------------------+-----+\n",
      "|site   |zoning        |property_type     |count|\n",
      "+-------+--------------+------------------+-----+\n",
      "|avito  |Service public|Terrains et fermes|2    |\n",
      "|avito  |NULL          |NULL              |5    |\n",
      "|avito  |Industriel    |Terrains et fermes|10   |\n",
      "|avito  |NULL          |Terrains et fermes|44   |\n",
      "|avito  |Immeuble      |Terrains et fermes|50   |\n",
      "|avito  |Villa         |Terrains et fermes|52   |\n",
      "|avito  |NULL          |Autre Immobilier  |56   |\n",
      "|avito  |Maison        |Terrains et fermes|57   |\n",
      "|avito  |Agricole      |Terrains et fermes|63   |\n",
      "|avito  |NULL          |Maisons           |118  |\n",
      "|avito  |NULL          |Bureaux           |364  |\n",
      "|avito  |NULL          |Local             |403  |\n",
      "|avito  |NULL          |Villas et Riads   |431  |\n",
      "|avito  |NULL          |Appartements      |2336 |\n",
      "|mubawab|NULL          |Maisons           |75   |\n",
      "|mubawab|NULL          |Local commercial  |117  |\n",
      "|mubawab|NULL          |Bureaux           |125  |\n",
      "|mubawab|NULL          |Terrains et fermes|194  |\n",
      "|mubawab|NULL          |Villas et Riads   |363  |\n",
      "|mubawab|NULL          |Appartements      |1467 |\n",
      "+-------+--------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"zoning\" , \"property_type\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "42341c20-e4fe-4cba-bb3b-c579efe0f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ zoning unified & normalized, type_de_terrain dropped.\n",
      "+---------------------------------------------------------+-----+\n",
      "|zoning                                                   |count|\n",
      "+---------------------------------------------------------+-----+\n",
      "|NULL                                                     |5920 |\n",
      "|villa lots                                               |107  |\n",
      "|agricultural                                             |85   |\n",
      "|house                                                    |57   |\n",
      "|building                                                 |50   |\n",
      "|residential cluster                                      |39   |\n",
      "|commercial                                               |26   |\n",
      "|industrial                                               |13   |\n",
      "|commercial, residential cluster                          |13   |\n",
      "|residential cluster, commercial                          |4    |\n",
      "|commercial, residential cluster, villa lots              |3    |\n",
      "|agricultural, residential cluster, commercial, villa lots|2    |\n",
      "|agricultural, commercial, industrial                     |2    |\n",
      "|commercial, industrial                                   |2    |\n",
      "|residential cluster, villa lots, agricultural            |2    |\n",
      "|public service                                           |2    |\n",
      "|agricultural, residential cluster, villa lots            |2    |\n",
      "|agricultural, commercial, villa lots                     |1    |\n",
      "|commercial, residential cluster, industrial, villa lots  |1    |\n",
      "|residential cluster, villa lots                          |1    |\n",
      "+---------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import unicodedata, re\n",
    "\n",
    "# --- utilitaires\n",
    "def _unaccent(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))\n",
    "\n",
    "def normalize_zoning(value: str) -> str:\n",
    "    if not value:\n",
    "        return None\n",
    "    s = _unaccent(value).lower().strip()\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    # d√©couper si plusieurs zones s√©par√©es par des virgules\n",
    "    parts = [p.strip() for p in s.split(\",\") if p.strip()]\n",
    "    \n",
    "    normalized = []\n",
    "    for p in parts:\n",
    "        if \"agricol\" in p:\n",
    "            normalized.append(\"agricultural\")\n",
    "        elif \"industriel\" in p:\n",
    "            normalized.append(\"industrial\")\n",
    "        elif \"commercial\" in p:\n",
    "            normalized.append(\"commercial\")\n",
    "        elif \"villa\" in p:\n",
    "            normalized.append(\"villa lots\")\n",
    "        elif \"groupement\" in p:\n",
    "            normalized.append(\"residential cluster\")\n",
    "        elif \"immeuble\" in p:\n",
    "            normalized.append(\"building\")\n",
    "        elif \"maison\" in p:\n",
    "            normalized.append(\"house\")\n",
    "        elif \"service public\" in p:\n",
    "            normalized.append(\"public service\")\n",
    "        else:\n",
    "            normalized.append(p)\n",
    "    \n",
    "    # retirer doublons et re-joindre\n",
    "    normalized = list(dict.fromkeys(normalized))\n",
    "    return \", \".join(normalized) if normalized else None\n",
    "\n",
    "normalize_zoning_udf = F.udf(normalize_zoning, \"string\")\n",
    "\n",
    "# --- fusionner et normaliser\n",
    "silver = (\n",
    "    silver.withColumn(\"zoning\", F.coalesce(F.col(\"zoning\"), F.col(\"type_de_terrain\")))\n",
    "          .withColumn(\"zoning\", normalize_zoning_udf(F.col(\"zoning\")))\n",
    "          .drop(\"type_de_terrain\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ zoning unified & normalized, type_de_terrain dropped.\")\n",
    "(\n",
    "    silver.groupBy(\"zoning\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(F.col(\"count\").desc())\n",
    "          .show(50, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c2753-6119-4faa-816e-01c0e3cc6d7e",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfe9c6-8ea4-4536-b201-7a56f1427720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"age_du_bien\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3501d18-35f6-483e-bc8a-b1b6a8c669c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"annees \") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1d85f89c-6fd4-49b3-a878-e7967013b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+\n",
      "|site   |age_du_bien        |count|\n",
      "+-------+-------------------+-----+\n",
      "|avito  |11-20 years        |15   |\n",
      "|avito  |More than 20 years |20   |\n",
      "|avito  |1-5 years          |28   |\n",
      "|avito  |6-10 years         |28   |\n",
      "|avito  |Less than 1 year   |68   |\n",
      "|avito  |NULL               |3832 |\n",
      "|mubawab|More than 100 years|2    |\n",
      "|mubawab|70-100 years       |4    |\n",
      "|mubawab|50-70 years        |4    |\n",
      "|mubawab|30-50 years        |22   |\n",
      "|mubawab|20-30 years        |48   |\n",
      "|mubawab|10-20 years        |184  |\n",
      "|mubawab|Less than 1 year   |246  |\n",
      "|mubawab|5-10 years         |299  |\n",
      "|mubawab|1-5 years          |466  |\n",
      "|mubawab|NULL               |1066 |\n",
      "+-------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, coalesce, trim\n",
    "from pyspark.sql.types import StringType\n",
    "import unicodedata, re\n",
    "\n",
    "def _unaccent(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", s)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "def normalize_age(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalise l'√¢ge du bien en anglais :\n",
    "    - \"Moins de 1 an\", \"Moins d'un an\" -> \"Less than 1 year\"\n",
    "    - \"1-5 ans\" -> \"1-5 years\"\n",
    "    - \"5-10 ans\" -> \"5-10 years\"\n",
    "    - \"6-10 ans\" -> \"6-10 years\"\n",
    "    - \"10-20 ans\" -> \"10-20 years\"\n",
    "    - \"11-20 ans\" -> \"11-20 years\"\n",
    "    - \"20-30 ans\" -> \"20-30 years\"\n",
    "    - \"30-50 ans\" -> \"30-50 years\"\n",
    "    - \"50-70 ans\" -> \"50-70 years\"\n",
    "    - \"70-100 ans\" -> \"70-100 years\"\n",
    "    - \"21+ ans\" -> \"More than 20 years\"\n",
    "    - \"Plus de 100 ans\" -> \"More than 100 years\"\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    raw = value.strip()\n",
    "    if raw == \"\":\n",
    "        return None\n",
    "\n",
    "    s = _unaccent(raw).lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # < 1 an\n",
    "    if s in {\"moins de 1 an\", \"moins d'un an\"}:\n",
    "        return \"Less than 1 year\"\n",
    "\n",
    "    # 1-5\n",
    "    if s == \"1-5 ans\":\n",
    "        return \"1-5 years\"\n",
    "\n",
    "    # 5-10\n",
    "    if s == \"5-10 ans\":\n",
    "        return \"5-10 years\"\n",
    "\n",
    "    # 6-10 (sp√©cifique Avito)\n",
    "    if s == \"6-10 ans\":\n",
    "        return \"6-10 years\"\n",
    "\n",
    "    # 10-20 (Mubawab)\n",
    "    if s == \"10-20 ans\":\n",
    "        return \"10-20 years\"\n",
    "\n",
    "    # 11-20 (Avito)\n",
    "    if s == \"11-20 ans\":\n",
    "        return \"11-20 years\"\n",
    "\n",
    "    # 20-30, 30-50, 50-70, 70-100\n",
    "    if s == \"20-30 ans\":\n",
    "        return \"20-30 years\"\n",
    "    if s == \"30-50 ans\":\n",
    "        return \"30-50 years\"\n",
    "    if s == \"50-70 ans\":\n",
    "        return \"50-70 years\"\n",
    "    if s == \"70-100 ans\":\n",
    "        return \"70-100 years\"\n",
    "\n",
    "    # Avito: 21+ ans\n",
    "    if s in {\"21+ ans\", \"21 ans et plus\"}:\n",
    "        return \"More than 20 years\"\n",
    "\n",
    "    # Mubawab: Plus de 100 ans\n",
    "    if s == \"plus de 100 ans\":\n",
    "        return \"More than 100 years\"\n",
    "\n",
    "    # valeurs vides / null-like\n",
    "    if s in {\"\", \"null\", \"none\"}:\n",
    "        return None\n",
    "\n",
    "    # fallback: retourner la version originale (trim)\n",
    "    return raw\n",
    "\n",
    "normalize_age_udf = F.udf(normalize_age, StringType())\n",
    "\n",
    "# -------- 1) fusion age_du_bien + annees dans age_du_bien --------\n",
    "silver = silver.withColumn(\n",
    "    \"age_du_bien\",\n",
    "    normalize_age_udf(\n",
    "        trim(coalesce(col(\"age_du_bien\"), col(\"annees\")))\n",
    "    )\n",
    ")\n",
    "\n",
    "# -------- 2) drop annees (on ne garde qu'une seule colonne) --------\n",
    "if \"annees\" in silver.columns:\n",
    "    silver = silver.drop(\"annees\")\n",
    "\n",
    "# -------- 3) sanity check --------\n",
    "(\n",
    "    silver.groupBy(\"site\", \"age_du_bien\")\n",
    "          .agg(F.count(\"*\").alias(\"count\"))\n",
    "          .orderBy(col(\"site\").asc(), col(\"count\").asc())\n",
    "          .show(100, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d3152-cba0-41b8-8003-3f94fbb73b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b490bbab-c6a7-45c8-9014-767c2f37b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+\n",
      "|site   |statut_du_terrain|count|\n",
      "+-------+-----------------+-----+\n",
      "|avito  |NULL             |278  |\n",
      "|mubawab|Non loti         |37   |\n",
      "|mubawab|Loti             |72   |\n",
      "|mubawab|NULL             |85   |\n",
      "+-------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "(\n",
    "    silver\n",
    "    .filter(col(\"property_type\") == \"Terrains et fermes\") \\\n",
    "    .groupBy(\"site\", \"statut_du_terrain\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(col(\"site\").asc(), col(\"count\").asc())\n",
    "    .show(100, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a61770-566e-430d-8690-418d98651199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "40ae9394-ec10-4df4-8ef9-c85d298f19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-----+\n",
      "|site   |constructibilite|count|\n",
      "+-------+----------------+-----+\n",
      "|avito  |NULL            |3991 |\n",
      "|mubawab|R+9             |1    |\n",
      "|mubawab|R+7             |2    |\n",
      "|mubawab|Plain pied      |7    |\n",
      "|mubawab|R+5             |8    |\n",
      "|mubawab|R+4             |14   |\n",
      "|mubawab|R+3             |18   |\n",
      "|mubawab|R+1             |26   |\n",
      "|mubawab|R+2             |32   |\n",
      "|mubawab|NULL            |2233 |\n",
      "+-------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"constructibilite\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8237e866-9d71-4e30-8d7e-53355b5dd142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- error: string (nullable = true)\n",
      " |-- ingest_ts: timestamp (nullable = true)\n",
      " |-- site: string (nullable = false)\n",
      " |-- offre: string (nullable = true)\n",
      " |-- price: decimal(38,0) (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- equipments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description_text: string (nullable = true)\n",
      " |-- surface_habitable: double (nullable = true)\n",
      " |-- caution: string (nullable = true)\n",
      " |-- zoning: string (nullable = true)\n",
      " |-- type_d_appartement: string (nullable = true)\n",
      " |-- surface_totale: double (nullable = true)\n",
      " |-- etage: string (nullable = true)\n",
      " |-- age_du_bien: string (nullable = true)\n",
      " |-- nombre_de_pieces: string (nullable = true)\n",
      " |-- chambres: string (nullable = true)\n",
      " |-- salle_de_bain: string (nullable = true)\n",
      " |-- frais_de_syndic_mois: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- disponibilite: string (nullable = true)\n",
      " |-- salons: string (nullable = true)\n",
      " |-- features_amenities_json: string (nullable = true)\n",
      " |-- type_de_bien: string (nullable = true)\n",
      " |-- statut_du_terrain: string (nullable = true)\n",
      " |-- type_du_sol: string (nullable = true)\n",
      " |-- constructibilite: string (nullable = true)\n",
      " |-- livraison: string (nullable = true)\n",
      " |-- orientation: string (nullable = true)\n",
      " |-- nombre_d_etages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ae720696-97e3-4cc7-ad4d-975b0a6057e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+\n",
      "|site   |offre_match|count|\n",
      "+-------+-----------+-----+\n",
      "|avito  |false      |5    |\n",
      "|avito  |true       |3986 |\n",
      "|mubawab|NULL       |2341 |\n",
      "+-------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"offre_match\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7716367b-6fe0-4fb2-bf09-33d21ad3f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Column 'offre_match' dropped successfully.\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- error: string (nullable = true)\n",
      " |-- ingest_ts: timestamp (nullable = true)\n",
      " |-- site: string (nullable = false)\n",
      " |-- offre: string (nullable = true)\n",
      " |-- price: decimal(38,0) (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- equipments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description_text: string (nullable = true)\n",
      " |-- surface_habitable: double (nullable = true)\n",
      " |-- zoning: string (nullable = true)\n",
      " |-- type_d_appartement: string (nullable = true)\n",
      " |-- surface_totale: double (nullable = true)\n",
      " |-- etage: string (nullable = true)\n",
      " |-- age_du_bien: string (nullable = true)\n",
      " |-- nombre_de_pieces: string (nullable = true)\n",
      " |-- chambres: string (nullable = true)\n",
      " |-- salle_de_bain: string (nullable = true)\n",
      " |-- frais_de_syndic_mois: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- disponibilite: string (nullable = true)\n",
      " |-- salons: string (nullable = true)\n",
      " |-- features_amenities_json: string (nullable = true)\n",
      " |-- statut_du_terrain: string (nullable = true)\n",
      " |-- constructibilite: string (nullable = true)\n",
      " |-- nombre_d_etages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop inutile column 'offre_match' from silver\n",
    "silver = silver.drop(\"offre_match\" , \"caution\" , \"orientation\" , \"livraison\" , \"type_du_sol\" , \"type_de_bien\")\n",
    "\n",
    "# V√©rification rapide\n",
    "print(\"‚úÖ Column 'offre_match' dropped successfully.\")\n",
    "silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "770c6f4a-f33a-44ed-b7b0-3bf0cdb9aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+\n",
      "|site   |disponibilite|count|\n",
      "+-------+-------------+-----+\n",
      "|avito  |3 mois       |24   |\n",
      "|avito  |2 mois       |43   |\n",
      "|avito  |+4 mois      |68   |\n",
      "|avito  |Imm√©diate    |623  |\n",
      "|avito  |NULL         |3233 |\n",
      "|mubawab|NULL         |2341 |\n",
      "+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"salons\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d8ac981d-226f-4cf2-9ba6-f24f067b993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|site   |salons|count|\n",
      "+-------+------+-----+\n",
      "|avito  |8     |3    |\n",
      "|avito  |638   |3    |\n",
      "|avito  |6     |3    |\n",
      "|avito  |7     |3    |\n",
      "|avito  |5     |12   |\n",
      "|avito  |4     |45   |\n",
      "|avito  |0     |93   |\n",
      "|avito  |3     |152  |\n",
      "|avito  |2     |415  |\n",
      "|avito  |NULL  |1505 |\n",
      "|avito  |1     |1757 |\n",
      "|mubawab|NULL  |2341 |\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"salons\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "eabf6f2b-987d-470c-bf94-aaee8d935284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+\n",
      "|site   |salle_de_bain|count|\n",
      "+-------+-------------+-----+\n",
      "|avito  |10           |2    |\n",
      "|avito  |15           |2    |\n",
      "|avito  |11           |3    |\n",
      "|avito  |18           |3    |\n",
      "|avito  |8            |5    |\n",
      "|avito  |7            |20   |\n",
      "|avito  |6            |27   |\n",
      "|avito  |5            |56   |\n",
      "|avito  |0            |114  |\n",
      "|avito  |4            |135  |\n",
      "|avito  |3            |267  |\n",
      "|avito  |NULL         |593  |\n",
      "|avito  |2            |1174 |\n",
      "|avito  |1            |1590 |\n",
      "|mubawab|NULL         |2341 |\n",
      "+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"salle_de_bain\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7a2b772d-5643-4995-9838-8d00eb0ac4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|site   |chambres|count|\n",
      "+-------+--------+-----+\n",
      "|avito  |20      |3    |\n",
      "|avito  |9       |4    |\n",
      "|avito  |10      |8    |\n",
      "|avito  |11      |9    |\n",
      "|avito  |7       |12   |\n",
      "|avito  |8       |13   |\n",
      "|avito  |6       |66   |\n",
      "|avito  |5       |142  |\n",
      "|avito  |4       |201  |\n",
      "|avito  |1       |516  |\n",
      "|avito  |3       |663  |\n",
      "|avito  |NULL    |1167 |\n",
      "|avito  |2       |1187 |\n",
      "|mubawab|NULL    |2341 |\n",
      "+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"chambres\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dc17d9ff-87ba-4d93-86f8-d6a4c736fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-----+\n",
      "|site   |nombre_de_pieces|count|\n",
      "+-------+----------------+-----+\n",
      "|avito  |9               |1    |\n",
      "|avito  |16              |1    |\n",
      "|avito  |50              |2    |\n",
      "|avito  |10              |4    |\n",
      "|avito  |8               |6    |\n",
      "|avito  |6               |11   |\n",
      "|avito  |4               |17   |\n",
      "|avito  |5               |36   |\n",
      "|avito  |2               |44   |\n",
      "|avito  |3               |80   |\n",
      "|avito  |1               |152  |\n",
      "|avito  |NULL            |3637 |\n",
      "|mubawab|NULL            |2341 |\n",
      "+-------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "silver.groupBy(\"site\", \"nombre_de_pieces\") \\\n",
    "      .agg(count(\"*\").alias(\"count\")) \\\n",
    "      .orderBy(col(\"site\").asc(), col(\"count\").asc()) \\\n",
    "      .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a5381355-6efa-4b8b-9763-925f5b589f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+-----+\n",
      "|site   |features_amenities_json                                                                                                                                                                                                                                                                                                                                            |title                                                                      |count|\n",
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+-----+\n",
      "|mubawab|[\"Garage\", \"Ascenseur\", \"Climatisation\"]                                                                                                                                                                                                                                                                                                                           |Appartement √† Louer de 112.0 m¬≤ √† Casablanca, Oasis                        |1    |\n",
      "|mubawab|[\"Jardin\", \"Terrasse\", \"Garage\", \"Ascenseur\", \"Vue sur mer\", \"Piscine\", \"Concierge\", \"Meubl√©\", \"Salon europ√©en\", \"Chemin√©e\", \"Climatisation\", \"Chauffage central\", \"S√©curit√©\", \"Double vitrage\", \"Porte blind√©e\", \"Cuisine √©quip√©e\", \"R√©frig√©rateur\", \"Four\", \"TV\", \"Machine √† laver\", \"Micro-ondes\"]                                                              |Appartement vide a louer ‚Äì R√©sidence Lotinord                              |1    |\n",
      "|mubawab|NULL                                                                                                                                                                                                                                                                                                                                                               |Bel appartement en location √† Tanja Balia. 2 belles chambres               |1    |\n",
      "|mubawab|[\"Garage\", \"Ascenseur\", \"Piscine\", \"Concierge\", \"Chambre rangement\", \"Meubl√©\", \"Fa√ßade ext√©rieure\", \"Salon Marocain\", \"Salon europ√©en\", \"Antenne parabolique\", \"Climatisation\", \"Chauffage central\", \"S√©curit√©\", \"Double vitrage\", \"Cuisine √©quip√©e\", \"R√©frig√©rateur\", \"Four\", \"TV\", \"Machine √† laver\", \"Micro-ondes\", \"Internet\", \"Animaux domestiques autoris√©s\"]|Tr√®s bon affaire √† nous pas rater sur Marrakech                            |1    |\n",
      "|mubawab|[\"Meubl√©\"]                                                                                                                                                                                                                                                                                                                                                         |Location Appartement √† m'hamid                                             |1    |\n",
      "|mubawab|[\"Terrasse\", \"Ascenseur\", \"Concierge\", \"Meubl√©\", \"Climatisation\", \"Chauffage central\", \"S√©curit√©\", \"Double vitrage\", \"Cuisine √©quip√©e\", \"TV\"]                                                                                                                                                                                                                      |Luxueux studio meubl√© √† louer √† Marrakech                                  |1    |\n",
      "|mubawab|[\"Jardin\", \"Piscine\", \"Concierge\", \"Chemin√©e\", \"Climatisation\", \"S√©curit√©\", \"Double vitrage\", \"Cuisine √©quip√©e\"]                                                                                                                                                                                                                                                   |LOCATION Appartement 2 chambres Vide Noria                                 |1    |\n",
      "|mubawab|[\"Jardin\", \"Terrasse\", \"Garage\", \"Ascenseur\", \"Concierge\", \"Chambre rangement\", \"Meubl√©\", \"Salon Marocain\", \"Salon europ√©en\", \"S√©curit√©\", \"Cuisine √©quip√©e\"]                                                                                                                                                                                                       |√Ä Louer Appartement Meubl√© avec double jardin                              |1    |\n",
      "|mubawab|[\"Jardin\", \"Terrasse\", \"Garage\", \"Vue sur mer\", \"Concierge\", \"Chambre rangement\", \"Meubl√©\", \"Salon Marocain\", \"Salon europ√©en\", \"Antenne parabolique\", \"Chemin√©e\", \"Climatisation\", \"S√©curit√©\", \"Porte blind√©e\", \"Cuisine √©quip√©e\", \"R√©frig√©rateur\", \"Four\", \"TV\", \"Machine √† laver\", \"Micro-ondes\", \"Internet\"]                                                   |Appartement √† louer √† Route Nationale Assilah. Surface totale 60 m¬≤. Meubl√©|1    |\n",
      "|mubawab|[\"Terrasse\", \"Concierge\", \"Chambre rangement\", \"Climatisation\"]                                                                                                                                                                                                                                                                                                    |Loue appartement 12 m                                                      |1    |\n",
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "(\n",
    "    silver.filter(col(\"site\") == \"mubawab\")\n",
    "          .groupBy(\"site\", \"equipment\" , \"title\")\n",
    "          .agg(count(\"*\").alias(\"count\"))\n",
    "          .orderBy(col(\"count\").asc())\n",
    "          .show(10, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb963e90-ed94-4e4c-b126-38e184b4d6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (container)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
